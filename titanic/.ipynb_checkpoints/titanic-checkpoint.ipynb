{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "- **Goal**\n",
    "You are asked to predict if a passenger survived the sinking of the Titanic or not. \n",
    "For each in the test set, we must predict a 0 or 1 value for the variable.\n",
    "- **Metric**\n",
    "Your score is the percentage of passengers you correctly predict. This is known simply as \"accuracyâ€.\n",
    "- **Submission File Format**\n",
    "You should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "\n",
    "PassengerId (sorted in any order)\n",
    "Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n",
    "~~~\n",
    "PassengerId,Survived\n",
    " 892,0\n",
    " 893,1\n",
    " 894,0\n",
    " Etc.\n",
    " ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Load Data\n",
    "First we have to select \"the most\" relevant features to use.\n",
    "After quick inspection of the train.csv file. I select `pclass, sex, age, sibsp, parch, fare, embarked`\n",
    "## 2.1 - Utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbify_data(df):\n",
    "    # Convert sex to numeric\n",
    "    df['Sex'].replace('female', 0, inplace=True)\n",
    "    df['Sex'].replace('male', 1, inplace=True)\n",
    "\n",
    "    # Convert embarked to numeric\n",
    "    df['Embarked'].replace('Q', 0, inplace=True)\n",
    "    df['Embarked'].replace('S', 1, inplace=True)\n",
    "    df['Embarked'].replace('C', 2, inplace=True)\n",
    "\n",
    "    # Replace nan age values by the mean of the available ages\n",
    "    age_mean = np.nanmean(df.Age.values)\n",
    "    df['Age'].fillna(age_mean, inplace=True)\n",
    "    \n",
    "    sibsp_mean = np.nanmean(df.SibSp.values)\n",
    "    df['SibSp'].fillna(sibsp_mean, inplace=True)\n",
    "    \n",
    "    parch_mean = np.nanmean(df.Parch.values)\n",
    "    df['Parch'].fillna(parch_mean, inplace=True)\n",
    "    \n",
    "    fare_mean = np.nanmean(df.Fare.values)\n",
    "    df['Fare'].fillna(fare_mean, inplace=True)\n",
    "    \n",
    "    #For missed values\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    \n",
    "def load_train_set():\n",
    "    df = pd.read_csv('train.csv', delimiter = ',')\n",
    "    df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    numbify_data(df)\n",
    "    train_set_x = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values.T\n",
    "    train_set_y = df[['Survived']].values.T\n",
    "    return train_set_x, train_set_y\n",
    "\n",
    "def load_test_set():\n",
    "    df = pd.read_csv('test.csv', delimiter = ',')\n",
    "    df = df[['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    numbify_data(df)\n",
    "    test_set_x = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values.T\n",
    "    test_set_id = df[['PassengerId']].values.T\n",
    "    return test_set_x, test_set_id\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Load training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y = load_train_set()\n",
    "test_set_x, test_set_id = load_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Overview of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 891\n",
      "Number of testing examples: m_test = 418\n"
     ]
    }
   ],
   "source": [
    "m_train = train_set_x.shape[1]\n",
    "m_test = test_set_x.shape[1]\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Building the parts of our algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Initializing parameters and help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_with_zeros(dim_features):\n",
    "    w = np.zeros((dim_features, 1))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim_features = train_set_x.shape[0]\n",
    "w, b = initialize_with_zeros(dim_features)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Forward and BackWard Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    #forward propagation\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = (-1/m) * np.sum(Y*np.log(A) + (1 - Y)*np.log(1-A))\n",
    "    \n",
    "    #backward propagation\n",
    "    dw = (1/m) * np.dot(X, (A-Y).T)\n",
    "    db = (1/m) * np.sum(A-Y)\n",
    "    \n",
    "    grads = {'dw': dw,\n",
    "            'db': db}\n",
    "    return grads, cost\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        w = w - learning_rate*grads['dw']\n",
    "        b = b - learning_rate*grads['db']\n",
    "        if print_cost and i % 10000 == 0:\n",
    "            print(\"cost after iteration\", i,\":\", cost)\n",
    "        costs.append(cost)\n",
    "    params = {'w': w,\n",
    "             'b': b}\n",
    "\n",
    "    grads = {'dw': grads['dw'],\n",
    "             'db': grads['db']}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after iteration 0 : 0.6931471805599454\n",
      "cost after iteration 10000 : 0.4790215030032276\n",
      "cost after iteration 20000 : 0.4660584107324556\n",
      "cost after iteration 30000 : 0.46007141327940915\n",
      "cost after iteration 40000 : 0.4558464863829955\n",
      "cost after iteration 50000 : 0.4526715716934283\n",
      "cost after iteration 60000 : 0.4502630388388405\n",
      "cost after iteration 70000 : 0.4484303263209077\n",
      "cost after iteration 80000 : 0.4470323144509472\n",
      "cost after iteration 90000 : 0.44596323120243064\n",
      "cost after iteration 100000 : 0.4451436478270597\n",
      "cost after iteration 110000 : 0.4445138188553954\n",
      "cost after iteration 120000 : 0.44402870218390145\n",
      "cost after iteration 130000 : 0.44365424849708596\n",
      "cost after iteration 140000 : 0.44336464284205107\n",
      "cost after iteration 150000 : 0.44314025447825967\n",
      "cost after iteration 160000 : 0.4429661111581356\n",
      "cost after iteration 170000 : 0.44283076106863994\n",
      "cost after iteration 180000 : 0.4427254214419925\n",
      "cost after iteration 190000 : 0.4426433395268757\n",
      "cost after iteration 200000 : 0.4425793112931223\n",
      "cost after iteration 210000 : 0.44252931767390086\n",
      "cost after iteration 220000 : 0.4424902487037701\n",
      "cost after iteration 230000 : 0.44245969362866283\n",
      "cost after iteration 240000 : 0.44243578071543066\n",
      "cost after iteration 250000 : 0.44241705463767106\n",
      "cost after iteration 260000 : 0.4424023823705639\n",
      "cost after iteration 270000 : 0.44239088078671435\n",
      "cost after iteration 280000 : 0.44238186082186776\n",
      "cost after iteration 290000 : 0.44237478432903843\n",
      "cost after iteration 300000 : 0.44236923067468453\n",
      "cost after iteration 310000 : 0.4423648708330403\n",
      "cost after iteration 320000 : 0.4423614472644769\n",
      "cost after iteration 330000 : 0.44235875826473064\n",
      "cost after iteration 340000 : 0.4423566457763735\n",
      "cost after iteration 350000 : 0.44235498588594774\n",
      "cost after iteration 360000 : 0.44235368140753284\n",
      "cost after iteration 370000 : 0.4423526560894297\n",
      "cost after iteration 380000 : 0.44235185008508604\n",
      "cost after iteration 390000 : 0.4423512164098229\n",
      "cost after iteration 400000 : 0.4423507181670076\n",
      "cost after iteration 410000 : 0.4423503263753373\n",
      "cost after iteration 420000 : 0.4423500182660952\n",
      "cost after iteration 430000 : 0.4423497759481145\n",
      "cost after iteration 440000 : 0.4423495853606162\n",
      "cost after iteration 450000 : 0.44234943545155336\n",
      "cost after iteration 460000 : 0.44234931753268686\n",
      "cost after iteration 470000 : 0.4423492247732386\n",
      "cost after iteration 480000 : 0.4423491518022421\n",
      "cost after iteration 490000 : 0.4423490943961858\n",
      "cost after iteration 500000 : 0.442349049233607\n",
      "cost after iteration 510000 : 0.4423490137022491\n",
      "cost after iteration 520000 : 0.44234898574750164\n",
      "cost after iteration 530000 : 0.4423489637532685\n",
      "cost after iteration 540000 : 0.44234894644831263\n",
      "cost after iteration 550000 : 0.44234893283262344\n",
      "cost after iteration 560000 : 0.4423489221195177\n",
      "cost after iteration 570000 : 0.44234891369011065\n",
      "cost after iteration 580000 : 0.4423489070575097\n",
      "cost after iteration 590000 : 0.4423489018386534\n",
      "cost after iteration 600000 : 0.4423488977321619\n",
      "cost after iteration 610000 : 0.44234889450091514\n",
      "cost after iteration 620000 : 0.44234889195834715\n",
      "cost after iteration 630000 : 0.442348889957666\n",
      "cost after iteration 640000 : 0.4423488883833725\n",
      "cost after iteration 650000 : 0.44234888714458775\n",
      "cost after iteration 660000 : 0.44234888616980483\n",
      "cost after iteration 670000 : 0.44234888540275813\n",
      "cost after iteration 680000 : 0.44234888479917484\n",
      "cost after iteration 690000 : 0.44234888432421804\n",
      "cost after iteration 700000 : 0.4423488839504758\n",
      "cost after iteration 710000 : 0.4423488836563783\n",
      "cost after iteration 720000 : 0.4423488834249527\n",
      "cost after iteration 730000 : 0.4423488832428432\n",
      "cost after iteration 740000 : 0.4423488830995405\n",
      "cost after iteration 750000 : 0.44234888298677494\n",
      "cost after iteration 760000 : 0.442348882898039\n",
      "cost after iteration 770000 : 0.4423488828282119\n",
      "cost after iteration 780000 : 0.44234888277326445\n",
      "cost after iteration 790000 : 0.4423488827300258\n",
      "cost after iteration 800000 : 0.44234888269600087\n",
      "cost after iteration 810000 : 0.4423488826692264\n",
      "cost after iteration 820000 : 0.4423488826481572\n",
      "cost after iteration 830000 : 0.44234888263157757\n",
      "cost after iteration 840000 : 0.442348882618531\n",
      "cost after iteration 850000 : 0.4423488826082644\n",
      "cost after iteration 860000 : 0.4423488826001855\n",
      "cost after iteration 870000 : 0.4423488825938281\n",
      "cost after iteration 880000 : 0.44234888258882543\n",
      "cost after iteration 890000 : 0.4423488825848887\n",
      "cost after iteration 900000 : 0.4423488825817909\n",
      "cost after iteration 910000 : 0.4423488825793531\n",
      "cost after iteration 920000 : 0.4423488825774349\n",
      "cost after iteration 930000 : 0.4423488825759253\n",
      "cost after iteration 940000 : 0.4423488825747375\n",
      "cost after iteration 950000 : 0.44234888257380267\n",
      "cost after iteration 960000 : 0.4423488825730672\n",
      "cost after iteration 970000 : 0.44234888257248833\n",
      "cost after iteration 980000 : 0.4423488825720328\n",
      "cost after iteration 990000 : 0.4423488825716744\n",
      "w = [[-1.06587870e+00]\n",
      " [-2.77454933e+00]\n",
      " [-3.92885838e-02]\n",
      " [-3.48754848e-01]\n",
      " [-1.16989637e-01]\n",
      " [ 2.66631128e-03]\n",
      " [ 1.23782587e-01]]\n",
      "b = 4.785001489524915\n"
     ]
    }
   ],
   "source": [
    "X = train_set_x\n",
    "Y = train_set_y\n",
    "np.nan_to_num(X, copy=False)\n",
    "np.nan_to_num(Y, copy=False)\n",
    "w, b = initialize_with_zeros(X.shape[0])\n",
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 1000000, learning_rate = 0.004, print_cost = True)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > .5 else 0 \n",
    "        pass\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 61.61616161616162 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_set_x\n",
    "Y_train = train_set_y\n",
    "\n",
    "np.nan_to_num(X_train, copy=False)\n",
    "np.nan_to_num(Y_train, copy=False)\n",
    "\n",
    "X_test = test_set_x\n",
    "np.nan_to_num(X_test, copy=False)\n",
    "\n",
    "Y_prediction_test = predict(w,b,X_test)\n",
    "Y_prediction_train = predict(w,b,X_train)\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "#print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "np.savetxt('submission.csv', np.hstack([test_set_id.T, Y_prediction_test.T]), delimiter=',')\n",
    "\n",
    "Y_prediction_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
